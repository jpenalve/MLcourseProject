{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from visualisations import eeg_sample_plot, events_distribution_plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import ChannelsVoltageDataset\n",
    "from neural_nets.nn_models_getter import get_nn_model\n",
    "from optimizers import get_optimizer\n",
    "from utils_train import fit, test, plot_all_metrics, plot_val_metrics\n",
    "from configs import configs_ozhan, configs_tim, configs_joaquin\n",
    "from data_loader_creation import get_dataloader_objects\n",
    "from classification_results import results_storer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" USER: SELECT THE CONFIGURATION YOU NEED \"\"\"\n",
    "#myList = configs_tim.list_of_configs\n",
    "#myList = configs_joaquin.list_of_configs\n",
    "myList = configs_ozhan.list_of_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet1D_Adam \n",
      "-------------------------\n",
      "\n",
      "We are not on the cluster...\n",
      "\n",
      "Data is being loaded using MNE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:32<00:00,  5.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5418 matching events found\n",
      "No baseline correction applied\n",
      "...data loading with MNE was finished. \n",
      "\n",
      "Data is being augmented with gaussian noise...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4388/4388 [00:32<00:00, 135.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...augmentation with gaussian noise is finished. \n",
      "\n",
      "cuda will be used for training of this model.\n",
      "You have 2 GPUs for training!\n",
      "Learning Rate:  0.001 \n",
      "\n",
      "-> Epoch 1/15: train_loss: 1.9599, train_accuracy: 22.4567%, val_loss: 1.7981, val_accuracy: 30.7377%\n",
      "-> Epoch 2/15: train_loss: 1.7235, train_accuracy: 34.2707%, val_loss: 1.7686, val_accuracy: 35.8607%\n",
      "-> Epoch 3/15: train_loss: 1.6946, train_accuracy: 35.1322%, val_loss: 1.7564, val_accuracy: 34.8361%\n",
      "-> Epoch 4/15: train_loss: 1.6675, train_accuracy: 36.5041%, val_loss: 1.7769, val_accuracy: 33.1967%\n",
      "-> Epoch 5/15: train_loss: 1.6557, train_accuracy: 37.2744%, val_loss: 1.7362, val_accuracy: 34.0164%\n",
      "-> Epoch 6/15: train_loss: 1.6372, train_accuracy: 37.7712%, val_loss: 1.7370, val_accuracy: 34.0164%\n",
      "-> Epoch 7/15: train_loss: 1.6093, train_accuracy: 39.0018%, val_loss: 1.7240, val_accuracy: 35.6557%\n",
      "-> Epoch 8/15: train_loss: 1.5981, train_accuracy: 39.2343%, val_loss: 1.7220, val_accuracy: 35.8607%\n",
      "-> Epoch 9/15: train_loss: 1.5825, train_accuracy: 40.2963%, val_loss: 1.7585, val_accuracy: 32.1721%\n",
      "-> Epoch 10/15: train_loss: 1.5647, train_accuracy: 40.7566%, val_loss: 1.7139, val_accuracy: 35.8607%\n",
      "-> Epoch 11/15: train_loss: 1.5546, train_accuracy: 41.5223%, val_loss: 1.7243, val_accuracy: 37.5000%\n",
      "-> Epoch 12/15: train_loss: 1.5474, train_accuracy: 41.6272%, val_loss: 1.7485, val_accuracy: 36.0656%\n",
      "-> Epoch 13/15: train_loss: 1.5464, train_accuracy: 41.4859%, val_loss: 1.7050, val_accuracy: 37.0902%\n",
      "-> Epoch 14/15: train_loss: 1.5345, train_accuracy: 42.3382%, val_loss: 1.7218, val_accuracy: 36.8852%\n"
     ]
    }
   ],
   "source": [
    "training_curves = {}\n",
    "\n",
    "for my_cfg in myList:\n",
    "    \n",
    "    curve_name = my_cfg.nn_list[my_cfg.nn_selection_idx] + \"_\" + my_cfg.optimizer_list[my_cfg.optimizer_selection_idx]\n",
    "    print(curve_name,\"\\n-------------------------\\n\", flush=True)\n",
    "    \n",
    "    \"\"\" PREPARE DATALOADERS \"\"\"\n",
    "    train_dl, val_dl, test_dl, input_dimension_, output_dimension_ = get_dataloader_objects(my_cfg)\n",
    "\n",
    "\n",
    "    \"\"\"CLASSIFICATION\"\"\"\n",
    "    # Get the model\n",
    "    model_untrained = get_nn_model(my_cfg.nn_list[my_cfg.nn_selection_idx], input_dimension=input_dimension_,\n",
    "                                   output_dimension=output_dimension_, dropout=my_cfg.dropout_perc)\n",
    "\n",
    "    # Get the optimizer\n",
    "    optimizer = get_optimizer(my_cfg.optimizer_list[my_cfg.optimizer_selection_idx], my_cfg.learning_rate,\n",
    "                              model_untrained.parameters(), my_cfg.momentum, my_cfg.weight_decay)\n",
    "\n",
    "    # Train and show validation loss\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies, model_trained, time_spent_for_training_s =\\\n",
    "        fit(train_dl, val_dl, model_untrained, optimizer, my_cfg.loss_fn, my_cfg.num_of_epochs, \\\n",
    "            scheduler=my_cfg.scheduler, apply_early_stopping = my_cfg.use_early_stopping, estop_patience=my_cfg.es_patience)\n",
    "    \n",
    "    \n",
    "    curves = train_losses, train_accuracies, val_losses, val_accuracies, model_trained, time_spent_for_training_s\n",
    "    \n",
    "    \n",
    "    training_curves[curve_name] = curves\n",
    "    \n",
    "    # Test the net\n",
    "    print('\\nPerformance on the test set:')\n",
    "    test_loss, test_accuracy = test(model_trained, test_dl, my_cfg.loss_fn, print_loss=True)\n",
    "    print('->test_loss: {:.4f}, test_accuracy: {:.4f}%'.format(test_loss, test_accuracy))\n",
    "\n",
    "\n",
    "    # Store the results\n",
    "    results_storer.store_results_for_plot(my_cfg,test_loss, test_accuracy, train_losses,\n",
    "                                 train_accuracies, time_spent_for_training_s, val_losses, val_accuracies)\n",
    "\n",
    "    results_storer.store_results(my_cfg, model_trained, optimizer, test_loss, test_accuracy, train_losses,\n",
    "                                 train_accuracies, time_spent_for_training_s, val_losses, val_accuracies, test_dl)\n",
    "\n",
    "\n",
    "plot_all_metrics(training_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
